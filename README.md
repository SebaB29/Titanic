# Titanic ğŸ›³ï¸
Trabajo PrÃ¡ctico para la materia **Base de Datos (TA044)**

## ğŸ“‘Contenido

1. [DescripciÃ³n](#descripciÃ³n)
2. [Integrantes](#integrantes)
3. [Objetivos](#objetivos)
4. [AnÃ¡lisis Exploratorio](#anÃ¡lisis-exploratorio)
5. [Preprocesamiento](#preprocesamiento)
6. [Conclusiones](#conclusiones)

## ğŸ“„DescripciÃ³n <a name="descripciÃ³n"></a>

<div align="justify">
Este trabajo prÃ¡ctico consiste en desarrollar una aplicaciÃ³n que implemente el proceso de <b>ETL</b> (Extract, Transform, Load) sobre un conjunto de datos. El objetivo es limpiar, transformar y cargar los datos en una base de datos SQLite, garantizando que estÃ©n listos para ser utilizados en anÃ¡lisis posteriores. Para esto, se ha seleccionado el famoso dataset de Titanic, disponible en Kaggle.
</div>

**Dataset**: https://www.kaggle.com/datasets/akshaysehgal/titanic-data-for-data-preprocessing

## ğŸ‘¥Integrantes <a name="integrantes"></a>

| Nombre                    |
|---------------------------|
| SebastiÃ¡n Brizuela        |
| Victoria Avalos           |
| Gonzalo Manuel CalderÃ³n   |
| Mateo Liberini            |
| Franco AgustÃ­n Rodriguez  |
| Urbano Sol Guadalupe      |

## ğŸ¯Objetivos <a name="objetivos"></a>

- Implementar un flujo de trabajo **ETL** que incluya la extracciÃ³n, transformaciÃ³n y carga de datos.
- Resolver problemas tÃ­picos de los datos, como valores nulos, duplicados y formatos inconsistentes.
- Garantizar que los datos estÃ©n listos para ser cargados y utilizados en una base de datos **SQLite**.

## ğŸ”AnÃ¡lisis Exploratorio <a name="anÃ¡lisis-exploratorio"></a>

<div align="justify">
El anÃ¡lisis comenzÃ³ con el dataset de Titanic, el cual contiene informaciÃ³n relevante de los pasajeros, como edad, sexo, y si sobrevivieron o no. Se realizÃ³ un anÃ¡lisis exploratorio para obtener una vista general del dataset, observando la cantidad de filas, columnas y valores faltantes. AdemÃ¡s, se generaron visualizaciones de la distribuciÃ³n de los datos y las relaciones entre las variables, como un boxplot para la distribuciÃ³n de la edad por sexo y un grÃ¡fico de barras para los valores nulos por columna.
</div>

## ğŸ› ï¸Preprocesamiento <a name="preprocesamiento"></a>

Durante el preprocesamiento se tomaron varias decisiones clave:
- EliminaciÃ³n de columnas redundantes como `male`, `class`, y `deck` (debido a gran cantidad de valores nulos).
- ImputaciÃ³n de valores nulos en la columna `age` basados en el promedio por sexo.
- EliminaciÃ³n de filas duplicadas, manteniendo un registro por pasajero y aÃ±adiendo una columna extra con el nÃºmero de duplicados.
- NormalizaciÃ³n de los datos para asegurar consistencia en el formato.
- Finalmente, los datos se cargaron en una base de datos SQLite.

## ğŸ“Conclusiones <a name="conclusiones"></a>

<div align="justify">
El proceso de ETL permitiÃ³ identificar problemas en los datos, como valores faltantes, redundancias y duplicados, que fueron solucionados a travÃ©s de tÃ©cnicas de preprocesamiento. La base de datos resultante estÃ¡ lista para consultas SQL, lo que permite realizar anÃ¡lisis avanzados de manera eficiente. Este proyecto destacÃ³ la importancia de un correcto flujo de ETL en la preparaciÃ³n de datos para su anÃ¡lisis y visualizaciÃ³n.
</div>

## ğŸ“„ Licencia  
Este proyecto estÃ¡ bajo la licencia MIT. Para mÃ¡s detalles, consulta el archivo [LICENSE](./LICENSE).
